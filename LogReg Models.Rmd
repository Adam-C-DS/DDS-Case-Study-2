---
title: "Attrition Models"
author: "Adam Canton"
date: "8/2/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ROCR)
library(magrittr)
library(tidyverse)
library(dplyr)
library(ggplot2)
library(naniar)
library(GGally)
library(e1071)
library(class)
library(caret)
library(MASS)
library(caret)
library(ggcorrplot)
library(Lahman)
library(olsrr)
library(glmnet)
```

```{r}
# Get data
cs2.data <- read.csv(file = "F:/R For Real/DDS-Case-Study-2/CaseStudy2-data.csv", sep = ",", header = TRUE)

exclude_factors = c("EmployeeCount",'Over18','StandardHours')
cs2.data = cs2.data %>% dplyr::select(-all_of(exclude_factors))

# Split data into sets of different data types 
cs2.data <- cs2.data %>% mutate(AttNum = ifelse(Attrition == "No",0,1))
cs2.numeric = cs2.data %>% dplyr::select(Age, DailyRate, DistanceFromHome, HourlyRate, MonthlyIncome, MonthlyRate, NumCompaniesWorked, PercentSalaryHike,
                                  TotalWorkingYears, TrainingTimesLastYear, YearsAtCompany, YearsInCurrentRole, YearsSinceLastPromotion,
                                  YearsWithCurrManager,AttNum)
```

```{r}
# Create Log Regression with Normal Variables Train and Test sets ----

cs2.yes <- subset(cs2.data, Attrition == "Yes")
cs2.no <- subset(cs2.data, Attrition == "No")

DimYes <- 100
DimNo <- 100

set.seed(35)
index.yes <- sample(1:dim(cs2.yes)[1],DimYes,replace=F)
train.yes <- cs2.yes[index.yes,]
test.yes <- cs2.yes[-index.yes,]

index.no <- sample(1:dim(cs2.no)[1],DimNo,replace=F)
train.no <- cs2.no[index.no,]
test.no <- cs2.no[-index.no,]

cs2.LogTrain <- rbind(train.no, train.yes)
cs2.LogTest <- rbind(test.no, test.yes)

exclude_factors <- c("ID", "AttNum")

cs2.LogTrain <- cs2.LogTrain %>% dplyr::select(-all_of(exclude_factors))
cs2.LogTest <- cs2.LogTest %>% dplyr::select(-all_of(exclude_factors))

# remove intermediate data sets
rm(test.no, test.yes, train.no, train.yes, cs2.no, cs2.yes)

```

```{r, warning = FALSE}
# Creates Step Model from Full 
full.log <- glm(Attrition ~ ., family = 'binomial', data = cs2.LogTrain)
step.log <- full.log %>% stepAIC(trace = FALSE)


summary(step.log) 

# Get predictions from Step Model
fit.pred.step <- predict(step.log, newdata = cs2.LogTest, type = "response")

p = data.frame(Att = cs2.LogTest$Attrition, Preds = fit.pred.step)
names(p)[2] <- 'Preds'
p %>% group_by(Att, Preds) %>% ggplot(aes(x = Preds, fill = Att)) + geom_boxplot() + facet_grid(rows = vars(p$Att))
```

```{r}
# Build Lasso Model on train set, finds optimal Lambda
cs2.Train.x <- model.matrix(Attrition ~ ., cs2.LogTrain)
cs2.Train.y <- cs2.LogTrain[,2]

cvfit <- cv.glmnet(cs2.Train.x, cs2.Train.y, family = "binomial", type.measure = "class", nlambda = 1000)

plot(cvfit)
coef(cvfit, s = "lambda.min")

# Cv Missclassification
print("Cv Error Rate:")
cvfit$cvm[which(cvfit$lambda==cvfit$lambda.min)]


# Optimal Penalty
print("Penalty Value:")
cvfit$lambda.min

# Final Model
finalmodel <- glmnet(cs2.Train.x, cs2.Train.y, family = "binomial", lambda = cvfit$lambda.min)
```

```{r}
# Get predictions from Lasso Model on Test set
cs2.Test.x <- model.matrix(Attrition ~ ., cs2.LogTest)

fit.pred.lasso <- predict(finalmodel, newx = cs2.Test.x, type = "response")

p = data.frame(Att = cs2.LogTest$Attrition, Preds = fit.pred.lasso)
names(p)[2] <- 'Preds'
p %>% group_by(Att, Preds) %>% ggplot(aes(x = Preds, fill = Att)) + geom_boxplot() + facet_grid(rows = vars(p$Att))

```

```{r}
# Custom Log - The best 16 by vizualization - now to pare it down
custom.log <- glm(Attrition ~ Age + DistanceFromHome + YearsWithCurrManager + TotalWorkingYears + YearsInCurrentRole + YearsAtCompany + MonthlyIncome + 
                    JobInvolvement + EducationField + EnvironmentSatisfaction + JobLevel + JobRole + MaritalStatus + OverTime + StockOptionLevel + 
                    WorkLifeBalance, family = "binomial", data = cs2.LogTrain)
summary(custom.log)

# Predictions
fit.pred.custom <- predict(custom.log, newdata = cs2.LogTest, type = "response")

p = data.frame(Att = cs2.LogTest$Attrition, Preds = fit.pred.custom)
names(p)[2] <- 'Preds'
p %>% group_by(Att, Preds) %>% ggplot(aes(x = Preds, fill = Att)) + geom_boxplot() + facet_grid(rows = vars(p$Att))

```

```{r}
# Top 3 Finder!
Top3.log <- glm(Attrition ~ JobRole + MaritalStatus + OverTime,
                family = "binomial",
                data = cs2.LogTrain)

summary(Top3.log)

# Predictions
fit.pred.Top3 <- predict(Top3.log, newdata = cs2.LogTest, type = "response")

p = data.frame(Att = cs2.LogTest$Attrition, Preds = fit.pred.Top3)
names(p)[2] <- 'Preds'
p %>% group_by(Att, Preds) %>% ggplot(aes(x = Preds, fill = Att)) + geom_boxplot() + facet_grid(rows = vars(p$Att))

# How'd it do?
cutoff.Top3 <- 0.5385

class.Top3 <- factor(ifelse(fit.pred.Top3 > cutoff.Top3, 'Yes','No'),levels = c('No','Yes'))
confusionMatrix(class.Top3, cs2.LogTest$Attrition)
```
```{r}
p.yes = subset(p, Att == "No") 
summary(p.yes)
```


```{r}
# Confusion Matrices!
cutoff.custom <- 0.5093134 
cutoff.lasso <- 0.5209
cutoff.step <- 0.55
cutoff.Top3 <- 0.5385


class.custom <- factor(ifelse(fit.pred.custom > cutoff.custom, 'Yes','No'),levels = c('No','Yes'))
class.lasso <- factor(ifelse(fit.pred.lasso > cutoff.lasso, 'Yes','No'),levels = c('No','Yes'))
class.step <- factor(ifelse(fit.pred.step > cutoff.step, "Yes", "No"), levels = c("No", "Yes"))
class.Top3 <- factor(ifelse(fit.pred.Top3 > cutoff.Top3, 'Yes','No'),levels = c('No','Yes'))

print("Confusion Lasso")
confusionMatrix(class.lasso, cs2.LogTest$Attrition)

cat("**********************************************\n**********************************************\n\n")

print("Confusion Step")
confusionMatrix(class.step, cs2.LogTest$Attrition)

cat("**********************************************\n**********************************************\n\n")

print("Confusion Custom")
confusionMatrix(class.custom, cs2.LogTest$Attrition)

cat("**********************************************\n**********************************************\n\n")

print("Confusion Top3")
confusionMatrix(class.Top3, cs2.LogTest$Attrition)

```

```{r}
# ROC Curves - since we are looking at the negative class (the Yes's of Attrition) we will be looking at the True and False Negative Rates
results.lasso <- prediction(fit.pred.lasso, cs2.LogTest$Attrition, label.ordering = c("No", "Yes"))
roc.lasso <- performance(results.lasso, measure = "tnr", x.measure = "fnr")

results.step <- prediction(fit.pred.step, cs2.LogTest$Attrition, label.ordering = c("No", "Yes"))
roc.step <- performance(results.step, measure = "tnr", x.measure = "fnr")

results.custom <- prediction(fit.pred.custom, cs2.LogTest$Attrition, label.ordering = c("No", "Yes"))
roc.custom <- performance(results.custom, measure = "tnr", x.measure = "fnr")

results.Top3 <- prediction(fit.pred.Top3, cs2.LogTest$Attrition, label.ordering = c("No", "Yes"))
roc.Top3 <- performance(results.Top3, measure = "tnr", x.measure = "fnr")

plot(roc.lasso, col = "red", main = "ROC")
plot(roc.step, col = "blue", add = TRUE)
plot(roc.custom, col = "green", add = TRUE)
plot(roc.Top3, col = "darkorchid4", add = TRUE)
abline(a = 0, b = 1)
legend("bottomright",legend=c("Lasso","Stepwise","Custom", "Top3"),col=c("red","blue","green", "darkorchid4"),lty=1,lwd=1)
```

```{r}
results.Knn <- prediction(prob, cs2.KNNTest$AttNum,)
roc.Knn <- performance(results.Knn, measure = "tnr", x.measure = "fnr")
```


```{r}
plot(roc.Top3, col = "darkorchid4", main = "ROC Comparison")
plot(roc.Knn, col = "orange", add = TRUE)
abline(a = 0, b = 1)
legend("bottomright",legend=c("Top3", "Knn"),col=c("darkorchid4", "orange"),lty=1,lwd=1)
```













